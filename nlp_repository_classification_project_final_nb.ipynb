{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "259a29c5",
   "metadata": {},
   "source": [
    "### Luis Arce, Lindy Castellaw, Jeremy Lagunas, Tim Keriazes\n",
    "\n",
    "#### Sep 8, 2022\n",
    "\n",
    "# NLP Github Classification Project - EndTheFed - Predicting #defi Repository Program Language From Readme Contents\n",
    "\n",
    "#### Scenario\n",
    "\n",
    "#### Project Description:\n",
    "##### Utilizing the contents of readme files within repositories on github, we set out to build a predictive model that would allow us to determine the programming language of the repository/project based on the contents of the readme. Utilizing web scraping techniques, we built a dataset containing the name of the repository, the programming language utilized, and the contents of the readme. Through some basic cleaning and preparation we will explore the dataset, looking for patterns, and creating some visualizations that show the most common words in the readme, whether the length varies by programming language, unique words, and any other identifying features. We will utilize the TfidfVectorizer() to transform the contents of the readme into features that will be fed into our predictive classification models.\n",
    "\n",
    "\n",
    "Project Planning/Outline:\n",
    "1. Investigating the repository search #defi\n",
    "2. Capture the urls/endpoints for all repos\n",
    "3. Flatten endpoints/utilize acquire.py file to interact with github api to pull repo name, language, and readme contents\n",
    "4. Data preparation/utilize prepare.py file to clean and prep data \n",
    "5. Exploration and Data Analysis/visualize dataset with analysis, word clouds, bigrams\n",
    "6. Split the dataset\n",
    "7. Model utilizing Tfidf vectorized readme contents\n",
    "8. Evaluate Models\n",
    "9. Test\n",
    "10. Conclusions/Next Steps\n",
    " \n",
    "\n",
    "#### Hypothesis\n",
    "1. Contents of readme will be indicative of programming language used\n",
    "\n",
    "### Target variable\n",
    "#### language\n",
    "\n",
    "### Exploration Key Findings/Results\n",
    "Explore and visualize the natural language data that you have acquired. Here are some ideas for exploration:\n",
    "\n",
    "#### 1. The most 10 most common words and the number of appearances in the readme were:\n",
    "        \n",
    "        contract    3914\n",
    "        token       3460\n",
    "        run         1740\n",
    "        1           1722\n",
    "        smart       1622\n",
    "        ethereum    1530\n",
    "        project     1530\n",
    "        address     1503\n",
    "        detail      1499\n",
    "        install     1438\n",
    "        \n",
    "\n",
    "#### 2. Length of the readme did vary by programming language\n",
    "#### 3. Javascript and Typescript utilized numeric characters/words much more so than other programming languages.\n",
    "#### 4. Of the 1000 repositories that we pulled, the most common language breakdown is as follows:\n",
    "\n",
    "        JavaScript\t\t0.237624\n",
    "        TypeScript\t\t0.221782\n",
    "        Solidity\t\t0.165347\n",
    "        Not Specified\t0.127723\n",
    "        Python\t\t    0.058416\n",
    "        Rust\t\t    0.031683\n",
    "        Go\t\t        0.025743\n",
    "\n",
    "#### 5. The top ten bigrams that appeared and their number of occurences across all languages were:\n",
    "\n",
    "        (smart, contract)                           1348\n",
    "        (git, clone)                                 759\n",
    "        (detail, detailssummaryba)                   670\n",
    "        (styledisplayinline, width13)                414\n",
    "        (npm, install)                               350\n",
    "        (srchttpsgitioj9co9, styledisplayinline)     342\n",
    "        (codeimg, srchttpsgitioj9co9)                341\n",
    "        (npm, run)                                   321\n",
    "        (decimal, 18)                                315\n",
    "        (chainid, 1)                                 309\n",
    "\n",
    "\n",
    "####  Best Model:\n",
    "\n",
    "### Key takeaways\n",
    "\n",
    "### Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f86387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import repo_github_api_acquire as aq\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "from env import github_token, github_username\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
