{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5fcabc7",
   "metadata": {},
   "source": [
    "### Luis Arce, Lindy Castellaw, Jeremy Lagunas, Tim Keriazes\n",
    "\n",
    "#### Sep 8, 2022\n",
    "\n",
    "# NLP Github Classification Project - EndTheFed - Predicting #defi Repository Program Language From Readme Contents\n",
    "\n",
    "#### Scenario\n",
    "\n",
    "#### Project Description:\n",
    "##### Utilizing the contents of readme files within repositories on github, we set out to build a predictive model that would allow us to determine the programming language of the repository/project based on the contents of the readme. Utilizing web scraping techniques, we built a dataset containing the name of the repository, the programming language utilized, and the contents of the readme. Through some basic cleaning and preparation we will explore the dataset, looking for patterns, and creating some visualizations that show the most common words in the readme, whether the length varies by programming language, unique words, and any other identifying features. We will utilize the TfidfVectorizer() to transform the contents of the readme into features that will be fed into our predictive classification models.\n",
    "\n",
    "\n",
    "Project Planning/Outline:\n",
    "1. Investigating the repository search #defi\n",
    "2. Capture the urls/endpoints for all repos\n",
    "3. Flatten endpoints/utilize acquire.py file to interact with github api to pull repo name, language, and readme contents\n",
    "4. Data preparation/utilize prepare.py file to clean and prep data \n",
    "5. Exploration and Data Analysis/visualize dataset with analysis, word clouds, bigrams\n",
    "6. Split the dataset\n",
    "7. Model utilizing Tfidf vectorized readme contents\n",
    "8. Evaluate Models\n",
    "9. Test\n",
    "10. Conclusions/Next Steps\n",
    " \n",
    "\n",
    "#### Hypothesis\n",
    "1. Contents of readme will be indicative of programming language used\n",
    "\n",
    "### Target variable\n",
    "#### language\n",
    "\n",
    "### Exploration Key Findings/Results\n",
    "Explore and visualize the natural language data that you have acquired. Here are some ideas for exploration:\n",
    "\n",
    "#### 1. The most 10 most common words and the number of appearances in the readme were:\n",
    "        \n",
    "        contract    3914\n",
    "        token       3460\n",
    "        run         1740\n",
    "        1           1722\n",
    "        smart       1622\n",
    "        ethereum    1530\n",
    "        project     1530\n",
    "        address     1503\n",
    "        detail      1499\n",
    "        install     1438\n",
    "        \n",
    "\n",
    "#### 2. Length of the readme did vary by programming language\n",
    "#### 3. Javascript and Typescript utilized numeric characters/words much more so than other programming languages.\n",
    "#### 4. Of the 1000 repositories that we pulled, the most common language breakdown is as follows:\n",
    "\n",
    "        JavaScript\t\t0.237624\n",
    "        TypeScript\t\t0.221782\n",
    "        Solidity\t\t0.165347\n",
    "        Not Specified\t0.127723\n",
    "        Python\t\t    0.058416\n",
    "        Rust\t\t    0.031683\n",
    "        Go\t\t        0.025743\n",
    "\n",
    "#### 5. The top ten bigrams that appeared and their number of occurences across all languages were:\n",
    "\n",
    "        (smart, contract)                           1348\n",
    "        (git, clone)                                 759\n",
    "        (detail, detailssummaryba)                   670\n",
    "        (styledisplayinline, width13)                414\n",
    "        (npm, install)                               350\n",
    "        (srchttpsgitioj9co9, styledisplayinline)     342\n",
    "        (codeimg, srchttpsgitioj9co9)                341\n",
    "        (npm, run)                                   321\n",
    "        (decimal, 18)                                315\n",
    "        (chainid, 1)                                 309\n",
    "\n",
    "\n",
    "# Best Model: \n",
    "### Refined Random Forest with max depth 6\n",
    "    - We established baseline using the mode language of Javascript which appeared 0.27 of all occurrences. Our final model predictions on the test set are 0.71\n",
    "\n",
    "### Key takeaways\n",
    "    - Javascript was the most occurring language \n",
    "    - All models beat the baseline \n",
    "### Next Steps\n",
    "    - Bring in other features like bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3ef0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "#import repo_github_api_acquire as aq\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import nlp_acquire\n",
    "import nlp_prepare\n",
    "import prepare_repos\n",
    "\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "from env import github_token, github_username\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02879909",
   "metadata": {},
   "source": [
    "### CreateURLs, get URL endpoints, flatten endpoints, establish final values, write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates Urls\n",
    "nlp_acquire.create_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes endpoints\n",
    "nlp_acquire.make_all_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire endpoints and write csv to local\n",
    "nlp_acquire.acquire_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv\n",
    "final_values = pd.read_csv('endpoints.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6400f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten values of df, Put to list so it can be used in helper file repo_github_api_acquire \n",
    "final_values = nlp_acquire.flatten_endpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish variable of final values for helper function\n",
    "REPOS = final_values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilize helper repo_github_api_acquire , input final_values.tolist() produces data.json on local machine\n",
    "#allows the json file to be read in as data\n",
    "with open('data.json', 'r') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d2a175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/OffcierCia/DeFi-Developer-Road-Map</td>\n",
       "      <td>None</td>\n",
       "      <td># DeFi Developer Road Map\\n\\n**Here we collect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/smartcontractkit/full-blockchain-solidity-cou...</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;!-- [YouTube Video](https://www.youtube.com/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/rainbow-me/rainbow</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>![](https://pbs.twimg.com/profile_banners/1103...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Bytom/bytom</td>\n",
       "      <td>Go</td>\n",
       "      <td>Bytom\\n======\\n\\n[![Build Status](https://trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/DimensionDev/Maskbook</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>&lt;!-- cspell:disable --&gt;\\n&lt;!-- markdownlint-dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo    language  \\\n",
       "0                /OffcierCia/DeFi-Developer-Road-Map        None   \n",
       "1  /smartcontractkit/full-blockchain-solidity-cou...        None   \n",
       "2                                /rainbow-me/rainbow  TypeScript   \n",
       "3                                       /Bytom/bytom          Go   \n",
       "4                             /DimensionDev/Maskbook  TypeScript   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  # DeFi Developer Road Map\\n\\n**Here we collect...  \n",
       "1  <!-- [YouTube Video](https://www.youtube.com/w...  \n",
       "2  ![](https://pbs.twimg.com/profile_banners/1103...  \n",
       "3  Bytom\\n======\\n\\n[![Build Status](https://trav...  \n",
       "4  <!-- cspell:disable -->\\n<!-- markdownlint-dis...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read it into a df\n",
    "df = pd.read_json('data.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15a6c99",
   "metadata": {},
   "source": [
    "### Repos scraped, language and contents pulled, readme contents ready to be cleaned and prepped\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "- handle nulls\n",
    "- tokenize\n",
    "- remove stopwords\n",
    "- lemmatize\n",
    "- create new df with new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ce3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo               0\n",
       "language           0\n",
       "readme_contents    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c49c7138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle the nulls\n",
    "df[\"language\"].fillna(\"Not Specified\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42326b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_languages = df.language.value_counts()[df.language.value_counts() > 4].index\n",
    "# Removing languages not kept\n",
    "df = df[df.language.isin(remaining_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54f94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readme_contents'] = df.readme_contents.apply(prepare_repos.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ecf4f21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/OffcierCia/DeFi-Developer-Road-Map</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>defi developer road map collect discus best de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/smartcontractkit/full-blockchain-solidity-cou...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>youtube video http www youtube com watch v m57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/rainbow-me/rainbow</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>http pb twimg com profile banner 1103191459409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Bytom/bytom</td>\n",
       "      <td>Go</td>\n",
       "      <td>bytom build status http travis ci org bytom by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/DimensionDev/Maskbook</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>cspell disable markdownlint disable inline htm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo       language  \\\n",
       "0                /OffcierCia/DeFi-Developer-Road-Map  Not Specified   \n",
       "1  /smartcontractkit/full-blockchain-solidity-cou...  Not Specified   \n",
       "2                                /rainbow-me/rainbow     TypeScript   \n",
       "3                                       /Bytom/bytom             Go   \n",
       "4                             /DimensionDev/Maskbook     TypeScript   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  defi developer road map collect discus best de...  \n",
       "1  youtube video http www youtube com watch v m57...  \n",
       "2  http pb twimg com profile banner 1103191459409...  \n",
       "3  bytom build status http travis ci org bytom by...  \n",
       "4  cspell disable markdownlint disable inline htm...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b032b",
   "metadata": {},
   "source": [
    "### Exploration, Data Analysis, Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d69af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#percentage of languages\n",
    "\n",
    "labels = pd.concat([df.language.value_counts(),\n",
    "                    df.language.value_counts(normalize=True)], axis=1)\n",
    "labels.columns = ['n', 'percent']\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86bcf23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_repo_content = nlp_acquire.read_url_or_file_repo()\n",
    "repo_df = nlp_prepare.make_dataframe(scrape_repo_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ea8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_df = nlp_prepare.make_dataframe(scrape_repo_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec37fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_STOPWORDS = []\n",
    "\n",
    "def clean(text):\n",
    "    'A simple function to cleanup text data'\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "             .encode('ascii', 'ignore')\n",
    "             .decode('utf-8', 'ignore')\n",
    "             .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#breaking out the words of each of the most used languages\n",
    "js_words = clean(' '.join(repo_df[repo_df.language == 'JavaScript'].readme_contents))\n",
    "ts_words = clean(' '.join(repo_df[repo_df.language == 'TypeScript'].readme_contents))\n",
    "notspec_words = clean(' '.join(repo_df[repo_df.language == 'Not Specified'].readme_contents))\n",
    "solidity_words = clean(' '.join(repo_df[repo_df.language == 'Solidity'].readme_contents))\n",
    "python_words= clean(' '.join(repo_df[repo_df.language == 'Python'].readme_contents))\n",
    "rust_words= clean(' '.join(repo_df[repo_df.language == 'Rust'].readme_contents))\n",
    "go_words= clean(' '.join(repo_df[repo_df.language == 'Go'].readme_contents))\n",
    "\n",
    "all_words = clean(' '.join(repo_df.readme_contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency of the words\n",
    "js_freq = pd.Series(js_words).value_counts()\n",
    "ts_freq = pd.Series(ts_words).value_counts()\n",
    "notspec_freq = pd.Series(notspec_words).value_counts()\n",
    "solidity_freq = pd.Series(solidity_words).value_counts()\n",
    "python_freq = pd.Series(python_words).value_counts()\n",
    "rust_freq = pd.Series(rust_words).value_counts()\n",
    "go_freq = pd.Series(go_words).value_counts()\n",
    "\n",
    "all_freq = pd.Series(all_words).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8825e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows word counts\n",
    "word_counts = (pd.concat([all_freq, js_freq, ts_freq, notspec_freq,solidity_freq, python_freq, rust_freq, go_freq], axis=1, sort=True)\n",
    "                .set_axis(['all', 'js', 'ts','notspec','solidity','python','rust','go'], axis=1, inplace=False)\n",
    "                .fillna(0)\n",
    "                .apply(lambda s: s.astype(int)))\n",
    "\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb13199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of unique wordcounts\n",
    "js_freq.nunique(),ts_freq.nunique(),notspec_freq.nunique(),solidity_freq.nunique(),python_freq.nunique(),rust_freq.nunique(),go_freq.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts.sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67388bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most used words\n",
    "word_counts['all'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baa7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the percentage of spam vs ham\n",
    "(word_counts\n",
    " .assign(p_js=word_counts.js / word_counts['all'],\n",
    "         p_ts=word_counts.ts / word_counts['all'],\n",
    "         p_notspec=word_counts.notspec / word_counts['all'],\n",
    "         p_solidity=word_counts.solidity / word_counts['all'],\n",
    "         p_python=word_counts.python / word_counts['all'],\n",
    "         p_rust=word_counts.rust / word_counts['all'],\n",
    "         p_go=word_counts.go / word_counts['all'] \n",
    "        )\n",
    " .sort_values(by='all')\n",
    " [['p_js', 'p_ts','p_notspec','p_solidity','p_python','p_rust','p_rust','p_go']]\n",
    " .tail(25)\n",
    " .sort_values('p_js')\n",
    " .plot.barh(stacked=True))\n",
    "\n",
    "plt.title('Proportion of Language for the 25 most common words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 20 bigrams\n",
    "top_20_allwords_bigrams = (pd.Series(nltk.ngrams(all_words, 2))\n",
    "                      .value_counts()\n",
    "                      .head(20))\n",
    "\n",
    "top_20_allwords_bigrams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4015a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams histogram\n",
    "top_20_allwords_bigrams.sort_values(ascending=False).plot.barh(color='pink', width=.9, figsize=(10, 6))\n",
    "\n",
    "plt.title('20 Most frequently occuring bigrams')\n",
    "plt.ylabel('Bigram')\n",
    "plt.xlabel('# Occurances')\n",
    "\n",
    "# make the labels pretty\n",
    "ticks, _ = plt.yticks()\n",
    "labels = top_20_allwords_bigrams.reset_index()['index'].apply(lambda t: t[0] + ' ' + t[1])\n",
    "_ = plt.yticks(ticks, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigrams Word Cloud\n",
    "data = {k[0] + ' ' + k[1]: v for k, v in top_20_allwords_bigrams.to_dict().items()}\n",
    "img = WordCloud(background_color='white', width=800, height=400).generate_from_frequencies(data)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f866e36",
   "metadata": {},
   "source": [
    "### Exploration Key Findings/Results\n",
    "Explore and visualize the natural language data that you have acquired. Here are some ideas for exploration:\n",
    "\n",
    "#### 1. The most 10 most common words and the number of appearances in the readme were:\n",
    "        \n",
    "        contract    3914\n",
    "        token       3460\n",
    "        run         1740\n",
    "        1           1722\n",
    "        smart       1622\n",
    "        ethereum    1530\n",
    "        project     1530\n",
    "        address     1503\n",
    "        detail      1499\n",
    "        install     1438\n",
    "        \n",
    "\n",
    "#### 2. Length of the readme did vary by programming language\n",
    "#### 3. Javascript and Typescript utilized numeric characters/words much more so than other programming languages.\n",
    "#### 4. Of the 1000 repositories that we pulled, the most common language breakdown is as follows:\n",
    "\n",
    "        JavaScript\t\t0.237624\n",
    "        TypeScript\t\t0.221782\n",
    "        Solidity\t\t0.165347\n",
    "        Not Specified\t0.127723\n",
    "        Python\t\t    0.058416\n",
    "        Rust\t\t    0.031683\n",
    "        Go\t\t        0.025743\n",
    "\n",
    "#### 5. The top ten bigrams that appeared and their number of occurences across all languages were:\n",
    "\n",
    "        (smart, contract)                           1348\n",
    "        (git, clone)                                 759\n",
    "        (detail, detailssummaryba)                   670\n",
    "        (styledisplayinline, width13)                414\n",
    "        (npm, install)                               350\n",
    "        (srchttpsgitioj9co9, styledisplayinline)     342\n",
    "        (codeimg, srchttpsgitioj9co9)                341\n",
    "        (npm, run)                                   321\n",
    "        (decimal, 18)                                315\n",
    "        (chainid, 1)                                 309\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e39a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb304cf",
   "metadata": {},
   "source": [
    "### Modeling - Classification\n",
    "baseline - 0.27\n",
    "1. decision tree\n",
    "2. random forest max depth 3\n",
    "3. random forest max depth 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08f18176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Not Specified\n",
       "1    Not Specified\n",
       "2       TypeScript\n",
       "3               Go\n",
       "4       TypeScript\n",
       "Name: language, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.language\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ff78f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/OffcierCia/DeFi-Developer-Road-Map</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>defi developer road map collect discus best de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/smartcontractkit/full-blockchain-solidity-cou...</td>\n",
       "      <td>Not Specified</td>\n",
       "      <td>youtube video http www youtube com watch v m57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/rainbow-me/rainbow</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>http pb twimg com profile banner 1103191459409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Bytom/bytom</td>\n",
       "      <td>Go</td>\n",
       "      <td>bytom build status http travis ci org bytom by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/DimensionDev/Maskbook</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>cspell disable markdownlint disable inline htm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                repo       language  \\\n",
       "0                /OffcierCia/DeFi-Developer-Road-Map  Not Specified   \n",
       "1  /smartcontractkit/full-blockchain-solidity-cou...  Not Specified   \n",
       "2                                /rainbow-me/rainbow     TypeScript   \n",
       "3                                       /Bytom/bytom             Go   \n",
       "4                             /DimensionDev/Maskbook     TypeScript   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  defi developer road map collect discus best de...  \n",
       "1  youtube video http www youtube com watch v m57...  \n",
       "2  http pb twimg com profile banner 1103191459409...  \n",
       "3  bytom build status http travis ci org bytom by...  \n",
       "4  cspell disable markdownlint disable inline htm...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b0219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data and feature selection \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df.readme_contents)\n",
    "y = df.language\n",
    "\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y,  test_size=.2)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test_val, y_test_val, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d2e45dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000000\n",
       "1     0.000000\n",
       "2     0.000000\n",
       "3     0.000000\n",
       "4     0.000000\n",
       "        ...   \n",
       "93    0.000000\n",
       "94    0.000000\n",
       "95    0.000000\n",
       "96    0.020017\n",
       "97    0.000000\n",
       "Name: language, Length: 98, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validate_df.loc[:,\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1057bdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# turn X_ into df with features \n",
    "X_train_df= pd.DataFrame(X_train.todense(), columns=tfidf.get_feature_names())\n",
    "X_validate_df= pd.DataFrame(X_validate.todense(), columns=tfidf.get_feature_names())\n",
    "X_test_df= pd.DataFrame(X_test.todense(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3643f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn y_ into df\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df for predictions\n",
    "predictions = pd.DataFrame({ \n",
    "    'actual': y_train.language\n",
    "})\n",
    "predictions['baseline'] = y_train[y_train['language'] == 'JavaScript'].shape[0] /y_train.shape[0]\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e3c02",
   "metadata": {},
   "source": [
    "Decision Tree\n",
    "\n",
    "max depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4dd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model on train\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "clf = clf.fit(X_train_df, y_train)\n",
    "\n",
    "plt.figure(figsize=(13, 7))\n",
    "plot_tree(clf, feature_names=X_train_df.columns, class_names=clf.classes_, rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put train predicitions into df\n",
    "predictions['DT'] = clf.predict(X_train_df)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train_df, y_train)))\n",
    "predictions['DT'] = clf.score(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596b1898",
   "metadata": {},
   "source": [
    "Random forest\n",
    "\n",
    "max depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc7692",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=3, min_samples_leaf=3, random_state=123)\n",
    "rf.fit(X_train_df, y_train)\n",
    "y_pred = rf.predict(X_train_df)\n",
    "y_pred_proba = rf.predict_proba(X_train_df)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train_df, y_train)))\n",
    "\n",
    "predictions['RF'] = rf.score(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e382f0",
   "metadata": {},
   "source": [
    "Refined random forest\n",
    "\n",
    "max depth 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(max_depth=6, min_samples_leaf=3, random_state=123)\n",
    "rf2.fit(X_train_df, y_train)\n",
    "\n",
    "y_pred = rf2.predict(X_train_df)\n",
    "y_pred_proba = rf2.predict_proba(X_train_df)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train_df, y_train)))\n",
    "\n",
    "predictions['RF2'] = rf2.score(X_train_df, y_train)\n",
    "\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56fbe21",
   "metadata": {},
   "source": [
    "# Testing on validate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df for validate predictions\n",
    "predictions_val = pd.DataFrame({ \n",
    "    'actual': y_validate.language\n",
    "})\n",
    "# add baseline to predictions tables \n",
    "predictions_val['baseline'] = y_train[y_train['language'] == 'JavaScript'].shape[0] /y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c97cc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decsion tree on validate\n",
    "\n",
    "predictions_val['DT_val'] = clf.predict(X_validate_df)\n",
    "\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_validate_df, y_validate)))\n",
    "predictions_val['DT_val'] = clf.score(X_validate_df, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest on validate\n",
    "\n",
    "rf2 = RandomForestClassifier(max_depth=6, min_samples_leaf=3, random_state=123)\n",
    "rf2.fit(X_validate_df, y_validate)\n",
    "\n",
    "y_pred = rf2.predict(X_validate_df)\n",
    "y_pred_proba = rf2.predict_proba(X_validate_df)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_validate_df, y_validate)))\n",
    "\n",
    "predictions_val['RF2_val'] = rf2.score(X_validate_df, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30465728",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b1e54",
   "metadata": {},
   "source": [
    "All of the models beat the baseline on the training and validate data, with the best performing one being refined random forest with a max depth of 6. That model will be used on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c506bcf",
   "metadata": {},
   "source": [
    "## Test on random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new df for test predictions\n",
    "predictions_test = pd.DataFrame({ \n",
    "    'actual': y_test.language\n",
    "})\n",
    "predictions_test['baseline'] = y_train[y_train['language'] == 'JavaScript'].shape[0] /y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a883d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest on test\n",
    "\n",
    "rf2 = RandomForestClassifier(max_depth=6, min_samples_leaf=3, random_state=123)\n",
    "rf2.fit(X_test_df, y_test)\n",
    "\n",
    "y_pred = rf2.predict(X_test_df)\n",
    "y_pred_proba = rf2.predict_proba(X_test_df)\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_test_df, y_test)))\n",
    "\n",
    "predictions_test['RF2_test'] = rf2.score(X_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e561d6",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "We found that the most popular languages were JavaScript, TypeScript, Solidity, and Python. The most common words used across all READMEs were contract, token, and run. Our final model (Random Forest max depth of 6) performed with an accuracy of 68.4%. We didn’t expect there to be so many repos that aren’t labeled with a language and we didn’t expect so many random numeric strings to show up during our Feature Engineering.\n",
    "\n",
    "If we had more time, we would investigate similarities across languages to see if we can determine the computing language used by unlabeled repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e92b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
